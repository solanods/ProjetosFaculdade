# -*- coding: utf-8 -*-
"""GRUPO 4 - Entrega I

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kwppgp69XzIjTzAnuLTbqpV8HgpRqg9x

**Identificação**: Solano Cruz Júnior (2919585), Rogério Dourado Felix (2892220), Newton Douglas da Silva Nascimento (2733408), Raimundo de Sousa Lima Filho (2709691)

---





# Tema: Natural Language Processing (NPL) para análise de sentimentos em postagens do Twitter

O uso de inteligência artificial e machine learning para atividades de mineração de textos da web se apresenta como uma riquíssima fonte de insights para a ciência de dados. Nesse contexto, frameworks de aprendizado de máquina como Sklearn, Keras e Tensorflow têm dominado a cena, realizando desde tarefas simples até a criação de autoresponders, bots, classificadores de texto e vários sistemas de diálogo que determinam o significado das frases. 

Um framework bastante poderoso e com uma curva de aprendizagem um pouco mais curta em relação aos já citados é a biblioteca Spacy. Escrita em Python, possui suporte para mais de 60 idiomas. De código aberto, foi projetada para construir sistemas de extração de informações ou de compreensão de linguagem natural. Também foi desenvolvida para uso em produção e fornece uma API concisa e fácil de usar.


> **Objetivo**

Esse projeto tem como objetivo treinar um modelo capaz de avaliar se uma determinada frase apresenta sentimento POSITIVO ou NEGATIVO. 

> **Especificação Técnica**


Dataset TREINO: Para desenvolvimento desse projeto, será utilizado o dataset
denominado Train50, disponível em:  https://github.com/solanods/ProjetosFaculdade/blob/main/Train50.csv.

Dataset TEST: https://github.com/solanods/ProjetosFaculdade/blob/main/Test.csv

Formato: As bases de dados estão em formato CSV. Train 50.csv possui 50mil registros e 5 colunas. Test.csv possui 5mil registros e 5 colunas.

Métodos de Pŕe-processamento: Será criada uma função em Python para a limpeza e pré-processamentos textuais

Letras minúsculas: serão priorizadas no case das strings.<br>
Nome do usuário: remoção do caractere (@)<br>
URLs: remoção<br>
Espaços em branco: remoção<br>
Emoticons: substituidos pelas strings "emocaopostiva", "emocaonegativa"<br>
Stop words: remoção<br>
Lematização: aplicação<br>
Pontuações: remoção<br>



Tarefa de Aprendizado: Será aplicado o algoritimo de minimização de erro de treinamento a partir do método: spacy.util.minibatch a cada 500 registros.

IMPORTAÇÃO E INSTALAÇÃO DAS BIBLIOTECAS
"""

!pip install -q spacy==2.2.3

#atualização da biblioteca Spacy para português
!python3 -m spacy download pt

import pandas as pd
import string
import spacy
import random
import seaborn as sns
import numpy as np
import re

#carregar os dados de treino
base_treinamento = pd.read_csv('/content/Train50.csv', delimiter=';')

base_treinamento.shape

base_treinamento.head()

#base de treino com 5000 registros.
#sentimento negativo label 0
#sentimento postivo label 1

base_treinamento['sentiment'].value_counts()

# o conjunto de dados possui duas colunas do tipo inteiro e três colunas do tipo string
base_treinamento.info()

#eliminamos as colunas que não vamos usar
base_treinamento.drop(['id', 'tweet_date', 'query_used'], axis = 1, inplace=True)

base_treinamento.head()

#confirmar que não há valores nulos no dataframe
base_treinamento.info()

"""BASE DE TESTE"""

#carregar os dados de teste
base_teste = pd.read_csv('/content/Test.csv', delimiter=';')

base_teste.head()

base_teste.shape

#vamos fazer a mesma limpeza e verificação na base de teste
base_teste.drop(['id', 'tweet_date', 'query_used'], axis = 1, inplace=True)

base_treinamento.info()

